{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n\nimport random\nfrom fastai.tabular import * \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Load the provided data into pandas dataframes\ndf_train = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ndf_test = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ndf_test = df_test.fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This is my feature engineering, it is in a function to make it easier to apply to both the validation and training sets\ndef prepdata(df):\n    # Created new columns from the existing ones. \n    df[['surname', 'salutation+firstname']] = df['Name'].str.split(',', n=1, expand = True)\n    df[['salutation', 'firstname']] = df['salutation+firstname'].str.split('.', n=1, expand = True)\n    df[['ticket_firsthalf', 'ticket_secondhalf']] = df['Ticket'].str.split(' ', n=1, expand = True)\n    #data[\"Team\"]= data[\"Team\"].str.split(\"t\", n = 1, expand = True) \n    df.drop(['PassengerId', 'Name', 'salutation+firstname', 'Ticket', 'firstname'], axis=1, inplace=True)\n    \n    df['Deck'] = ''\n    for index, row in df.iterrows():\n        try:\n            if df.at[index, 'Cabin'] != 'None':\n                df.at[index, 'Deck'] = df.at[index, 'Cabin'][0]\n        except TypeError as e:\n            pass\n        \n    # Drop the columns that contain duplicate data or that I don't think add any value\n    # For you 'don't think' should mean, 'carefully tested multiple times and have been clearly demonstrated to reduce performance'\n    df.drop(['Deck', 'Cabin', 'ticket_firsthalf', 'ticket_secondhalf'], axis=1, inplace=True)\n\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply the data prep code to obtain the features we will use to train our model\ndf_train = prepdata(df_train)\ndf_test = prepdata(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Have a look at them, always interesting, always a good idea to make sure we know what is going into our models\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Never hurts to make sure the data still looks how we expect, it is surprisingly easy to mistakingly drop a column\ndf_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The dependent variable is what we will try to predict\ndep_var = 'Survived'\n#cat_names = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Cabin', 'Embarked', 'surname', 'salutation', 'ticket_firsthalf', 'ticket_secondhalf', 'Deck' ]\ncat_names = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked', 'surname', 'salutation']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The validation set will be take as a random sample from the provided data, we need the indicies within training dataframe\nvalid_idx = random.sample(range(1, len(df_train)), 200)\n\n# Processors are functions that will be applied to the data up front. \nprocs = [FillMissing, Categorify, Normalize]\n\n# This code creates a structure that contains our fully prepared data ready for the model\ndata = TabularDataBunch.from_df('/kaggle/output/', df_train, dep_var, valid_idx, test_df=df_test, procs=procs, cat_names=cat_names)\nprint(data.train_ds.cont_names)  # `cont_names` defaults to: set(df)-set(cat_names)-{dep_var}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a model that will be appropriate for our data\n# wd = weight decay\n\nlearn = tabular_learner(data, layers=[50,2], metrics=accuracy, wd=0.1, ps=[0.7], emb_drop=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find a good learning rate\nlearn.lr_find()\nlearn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit your model to the data\n#learn.fit_one_cycle(7, 5e-3)\nlearn.fit_one_cycle(14, 8e-2)\nlearn.fit_one_cycle(20, 5e-4)\n#learn.fit_one_cycle(50, 5e-3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Examine the losses from the training (only shows you the most recent training run)\nlearn.recorder.plot_losses()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate predictions on the test set. The test set is data that was provided to us by Kaggle, it is seperate from the training \n# Data because it has no labels. We will calculate predictions for these passengers and submit the results.\npreds, _ = learn.get_preds(ds_type=DatasetType.Test)\npred_prob, pred_class = preds.max(1)\ndf_test = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\nsubmission = pd.DataFrame({'PassengerId':df_test['PassengerId'],'Survived':pred_class})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Output our submission to csv\nsubmission.to_csv('my_submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}